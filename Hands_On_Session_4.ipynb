{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "You work for an environmental protection agency as a researcher. The leadership of your organization is trying to embark on a project to gain insight into public opinion on social media about\n",
        "climate issues. As a first task, your direct supervisor needs details of different posts in three subreddits - ‘climatechange’ , ‘climate’ and ‘globalwarming’. Therefore, you are faced with following\n",
        "responsibilities;\n",
        "1. Scrape the top 100 posts in each of the three subreddits. Call the object ‘top 300 posts’ and\n",
        "save it in a csv file.\n",
        "2. From the ‘top 300 posts’, filter out posts from the ‘climatechange’ subreddits with over 100\n",
        "comments. Call the object ‘cc highcomments’ and save it in a csv file.\n",
        "Submit your notebook (.ipynb) in the appropriate submission folder before the deadline"
      ],
      "metadata": {
        "id": "2a1QdQNyVL6Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXusoRKfUzUx",
        "outputId": "edd78146-3bba-478b-eed8-da86cbd4088b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: praw in /usr/local/lib/python3.8/dist-packages (7.6.1)\n",
            "Requirement already satisfied: update-checker>=0.18 in /usr/local/lib/python3.8/dist-packages (from praw) (0.18.0)\n",
            "Requirement already satisfied: prawcore<3,>=2.1 in /usr/local/lib/python3.8/dist-packages (from praw) (2.3.0)\n",
            "Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.8/dist-packages (from praw) (1.5.1)\n",
            "Requirement already satisfied: requests<3.0,>=2.6.0 in /usr/local/lib/python3.8/dist-packages (from prawcore<3,>=2.1->praw) (2.25.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (4.0.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         id                                              title  score  \\\n",
            "0    aqdmbz  I'm afraid climate change is going to kill me!...    614   \n",
            "1    gwe10x               This news article from 108 years ago    530   \n",
            "2    y2ev7z           Equip me in the debate on global warming    479   \n",
            "3    w83diw          They knew. They knew a hundred years ago.    453   \n",
            "4    bj69yj  Surface area of solar panels required to power...    371   \n",
            "..      ...                                                ...    ...   \n",
            "295  w4g7le              They know who's behind global warming     33   \n",
            "296  v7gakb  As the Great Salt Lake Dries Up, Utah Faces An...     36   \n",
            "297  uy7etv  1.5 degrees Paris climate target not ‘safe or ...     38   \n",
            "298  pny6o4  Can the USA's government reverse global warmin...     39   \n",
            "299  kiabz7  China is the world's largest polluter emitting...     36   \n",
            "\n",
            "     num_comments                                                url  \\\n",
            "0             413  https://www.reddit.com/r/climatechange/comment...   \n",
            "1              15                https://i.redd.it/mb39tcal2v251.jpg   \n",
            "2             224  https://www.reddit.com/r/climatechange/comment...   \n",
            "3             103  https://www.reddit.com/r/climatechange/comment...   \n",
            "4             129  https://i.pinimg.com/originals/4e/dc/50/4edc50...   \n",
            "..            ...                                                ...   \n",
            "295             1                    https://v.redd.it/1qqrqowtfuc91   \n",
            "296             2  https://www.nytimes.com/2022/06/07/climate/sal...   \n",
            "297             5  https://www.climatecodered.org/2022/05/15-degr...   \n",
            "298            38  https://www.reddit.com/r/GlobalWarming/comment...   \n",
            "299             3        http://tree-nation.clickablecard.top/sgTUQC   \n",
            "\n",
            "         subreddit  \n",
            "0    climatechange  \n",
            "1    climatechange  \n",
            "2    climatechange  \n",
            "3    climatechange  \n",
            "4    climatechange  \n",
            "..             ...  \n",
            "295  globalwarming  \n",
            "296  globalwarming  \n",
            "297  globalwarming  \n",
            "298  globalwarming  \n",
            "299  globalwarming  \n",
            "\n",
            "[300 rows x 6 columns]\n",
            "        id                                              title  score  \\\n",
            "0   aqdmbz  I'm afraid climate change is going to kill me!...    614   \n",
            "1   y2ev7z           Equip me in the debate on global warming    479   \n",
            "2   w83diw          They knew. They knew a hundred years ago.    453   \n",
            "3   bj69yj  Surface area of solar panels required to power...    371   \n",
            "4   w1csv9   Is the European heat wave due to climate change?    219   \n",
            "5   tm48p2  Does anyone else feel like their opportunity t...    207   \n",
            "6   ukn0cn  Honest question: Why does the public not get w...    185   \n",
            "7   ruo6vf  Former climate change denier here. This has be...    178   \n",
            "8   p1ybk6                   Climate anxiety as a 14 year old    181   \n",
            "9   do0jlg  Here’s a Mega-List of reputable sources provin...    162   \n",
            "10  o2scjk  It's fucking 115 f in the midwest US now and j...    157   \n",
            "11  x0uqjw  I am 13 and just want to live a normal life li...    149   \n",
            "12  bsfhd6  Polish scientists to Germany: Let's not get ri...    147   \n",
            "\n",
            "    num_comments                                                url  \\\n",
            "0            413  https://www.reddit.com/r/climatechange/comment...   \n",
            "1            224  https://www.reddit.com/r/climatechange/comment...   \n",
            "2            103  https://www.reddit.com/r/climatechange/comment...   \n",
            "3            129  https://i.pinimg.com/originals/4e/dc/50/4edc50...   \n",
            "4            184  https://www.reddit.com/r/climatechange/comment...   \n",
            "5            110  https://www.reddit.com/r/climatechange/comment...   \n",
            "6            111  https://www.reddit.com/r/climatechange/comment...   \n",
            "7            111  https://www.reddit.com/r/climatechange/comment...   \n",
            "8            131  https://www.reddit.com/r/climatechange/comment...   \n",
            "9            133  https://www.reddit.com/r/climatechange/comment...   \n",
            "10           114  https://www.reddit.com/r/climatechange/comment...   \n",
            "11           146  https://www.reddit.com/r/climatechange/comment...   \n",
            "12           183  http://fota4climate.org/2019/05/13/an-open-let...   \n",
            "\n",
            "        subreddit  \n",
            "0   climatechange  \n",
            "1   climatechange  \n",
            "2   climatechange  \n",
            "3   climatechange  \n",
            "4   climatechange  \n",
            "5   climatechange  \n",
            "6   climatechange  \n",
            "7   climatechange  \n",
            "8   climatechange  \n",
            "9   climatechange  \n",
            "10  climatechange  \n",
            "11  climatechange  \n",
            "12  climatechange  \n"
          ]
        }
      ],
      "source": [
        "#import packages\n",
        "!pip install praw\n",
        "import requests\n",
        "import pandas as pd\n",
        "import praw\n",
        "\n",
        "###Step 1\n",
        "\n",
        "#passing my details \n",
        "reddit = praw.Reddit(client_id=\"1UVcjLahdL12WrZo0xKmOQ\", client_secret=\t\"ARweQibBBqqThq4MHb-5KkLg-2CrOQ\", user_agent=\"Scrapping - 301\") \n",
        "\n",
        "#putting subreddit data in the name 'gw_sub_data'\n",
        "gw_sub_data = reddit.subreddit('GlobalWarming') #https://www.reddit.com/r/GlobalWarming/hot/ \n",
        "\n",
        "#defining the subreddits to scrape\n",
        "subreddits = [\"climatechange\", \"climate\", \"globalwarming\"]\n",
        "\n",
        "#defining an empty list to store the top 100 posts from each subreddit\n",
        "top_300_posts = []\n",
        "\n",
        "#scraping the top 100 posts from each subreddit and putting them in the list\n",
        "for subreddit in subreddits:\n",
        "    top_100_posts = reddit.subreddit(subreddit).top(limit=100)\n",
        "    for post in top_100_posts:\n",
        "        top_300_posts.append([post.id, post.title, post.score, post.num_comments, post.url, subreddit])\n",
        "\n",
        "#converting the list of the top 300 posts to a pandas dataframe\n",
        "df = pd.DataFrame(top_300_posts, columns=['id', 'title', 'score', 'num_comments', 'url', 'subreddit'])\n",
        "\n",
        "#saving the dataframe to a csv file\n",
        "df.to_csv('top_300_posts.csv', index=False)\n",
        "\n",
        "#reading the csv file back into a dataframe to print it\n",
        "df_from_csv = pd.read_csv('top_300_posts.csv')\n",
        "print(df_from_csv)\n",
        "\n",
        "###Step 2\n",
        "\n",
        "#filtering posts from 'climatechange' subreddit with over 100 comments\n",
        "cc_highcomments = df[(df['subreddit'] == 'climatechange') & (df['num_comments'] > 100)]\n",
        "\n",
        "#saving filtered dataframe to a CSV file\n",
        "cc_highcomments.to_csv('cc_highcomments.csv', index=False)\n",
        "\n",
        "#reading the CSV file back into a dataframe\n",
        "df_cc_highcomments = pd.read_csv('cc_highcomments.csv')\n",
        "\n",
        "#printing the dataframe\n",
        "print(df_cc_highcomments)"
      ]
    }
  ]
}